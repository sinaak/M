{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is for training different ML models on different kind of vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from sklearn.pipeline import Pipeline\n",
    "from molearn.classifiers.BR import BR\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from molearn.classifiers.Ensemble import Ensemble\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from molearn.classifiers.classifier_chains import CC,RCC,MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Hamming_loss(Ytest,Ypred):\n",
    "    ''' Hamming loss aka Hamming distance '''\n",
    "    return 1.-Hamming_score(Ytest,Ypred)\n",
    "\n",
    "def Hamming_score(Ytest,Ypred):\n",
    "    ''' Hamming score aka Hamming match '''\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum((Ytest == Ypred) * 1.) / N_test / L\n",
    "\n",
    "def Hamming_matches(Ytest,Ypred):\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum((Ytest == Ypred) * 1.,axis=0) / N_test \n",
    "\n",
    "def Hamming_losses(Ytest,Ypred):\n",
    "    return 1.-Hamming_matches(Ytest,Ypred)\n",
    "\n",
    "def Exact_match(Ytest,Ypred):\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum(np.sum((Ytest == Ypred) * 1,axis=1)==L) * 1. / N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(train_x, train_y, test_x, test_y, parameters, pipeline):\n",
    "    grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=3, verbose=10)\n",
    "    grid_search_tune.fit(train_x, train_y)\n",
    "\n",
    "    print\n",
    "    print(\"Best parameters set:\")\n",
    "    print (grid_search_tune.best_estimator_.steps)\n",
    "    print\n",
    "\n",
    "    # measuring performance on test set\n",
    "    print (\"Applying best classifier on test data:\")\n",
    "    best_clf = grid_search_tune.best_estimator_\n",
    "    \n",
    "    predictions = best_clf.predict(test_x)\n",
    "    print('grid_search_tune.best_estimator : ',grid_search_tune.best_estimator_.steps[0])\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "def save_model(clf,filename,folder):\n",
    "    pickle.dump(clf, open(\"/home/sina/trained-model/\"+folder+\"/\"+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bp_mll_loss(y_true, y_pred):\n",
    " \n",
    "    # get true and false labels\n",
    "    y_i = K.equal(y_true, K.ones_like(y_true))\n",
    "    y_i_bar = K.not_equal(y_true, K.ones_like(y_true))\n",
    "    \n",
    "    # cast to float as keras backend has no logical and\n",
    "    y_i = K.cast(y_i, dtype='float32')\n",
    "    y_i_bar = K.cast(y_i_bar, dtype='float32')\n",
    "\n",
    "    # get indices to check\n",
    "    truth_matrix = pairwise_and(y_i, y_i_bar)\n",
    "\n",
    "    # calculate all exp'd differences\n",
    "    sub_matrix = pairwise_sub(y_pred, y_pred)\n",
    "    exp_matrix = K.exp(-sub_matrix)\n",
    "\n",
    "    # check which differences to consider and sum them\n",
    "    sparse_matrix = exp_matrix * truth_matrix\n",
    "    sums = K.sum(sparse_matrix, axis=[1,2])\n",
    "\n",
    "    # get normalizing terms and apply them\n",
    "    y_i_sizes = K.sum(y_i, axis=1)\n",
    "    y_i_bar_sizes = K.sum(y_i_bar, axis=1)\n",
    "    normalizers = y_i_sizes * y_i_bar_sizes\n",
    "    results = sums / normalizers\n",
    "\n",
    "    # sum over samples\n",
    "    return K.sum(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# compute pairwise differences between elements of the tensors a and b\n",
    "def pairwise_sub(a, b):\n",
    "    column = K.expand_dims(a, 2)\n",
    "    row = K.expand_dims(b, 1)\n",
    "    return column - row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute pairwise logical and between elements of the tensors a and b\n",
    "def pairwise_and(a, b):\n",
    "    column = K.expand_dims(a, 2)\n",
    "    row = K.expand_dims(b, 1)\n",
    "    return K.minimum(column, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        \"clf__estimator__C\": [0.1,1,10],\n",
    "        \"clf__estimator__class_weight\": [None],\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaboost(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    algorithm=\"SAMME\"), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        \"clf__estimator__learning_rate\": [1,1.5],\n",
    "        \"clf__estimator__n_estimators\": [6],\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naivebayes(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "\n",
    "\n",
    "    print (\"LinearSVC\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(SVC(), n_jobs=-1)),\n",
    "    ])\n",
    "    \n",
    "    parameters ={\n",
    "         'clf__estimator__kernel': ['rbf'],\n",
    "         'clf__estimator__gamma': [1e-3],\n",
    "         'clf__estimator__C': [10]\n",
    "        }\n",
    "        \n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape:  (200000, 300)\n",
      "y_data shape:  (200000, 28)\n"
     ]
    }
   ],
   "source": [
    "x_data = pd.read_csv('/home/sina/input/Word2Vec/x_embeddings_Word2Vec.csv')\n",
    "y_data = pd.read_csv('/home/sina/input/Word2Vec/y_data_Word2Vec.csv')\n",
    "x_data = x_data.as_matrix()\n",
    "y_data = y_data.as_matrix()\n",
    "x_data = x_data[0:200000]\n",
    "y_data = y_data[0:200000]\n",
    "print('x_data shape: ', x_data.shape)\n",
    "print('y_data shape: ', y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Split data to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 shape of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (134000, 300)\n",
      "y_train shape:  (134000, 28)\n",
      "x_test shape:  (66000, 300)\n",
      "y_test shape:  (66000, 28)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 apply different algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.1 OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.1017910447761194, total=   9.4s\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.09970149253731343, total=   9.6s\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   6 | elapsed:    9.8s remaining:   19.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.15417910447761193, total=  12.6s\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   6 | elapsed:   12.9s remaining:   12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.1591044776119403, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   4 out of   6 | elapsed:   22.1s remaining:   11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.15940298507462686, total=  37.6s\n",
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.15895522388059702, total=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:   50.4s finished\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:   50.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))]\n",
      "Applying best classifier on test data:\n",
      "grid_search_tune.best_estimator :  ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))\n"
     ]
    }
   ],
   "source": [
    "bst_clf_logisticregression_OneVsRestClassifier_Word2Vec=logisticRegression(x_train, x_test, y_train, y_test)\n",
    "save_model(bst_clf_logisticregression_OneVsRestClassifier_Word2Vec,'logisticregression_OneVsRestClassifier_Word2Vec.sav','Word2Vec')\n",
    "prediction_logisticregression_OneVsRestClassifier_Word2Vec = bst_clf_logisticregression_OneVsRestClassifier_Word2Vec.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.2 ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=6)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=7)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=9)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains = [ClassifierChain(LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_chains = np.array([chain.predict(x_test) for chain in\n",
    "                          chains])\n",
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec = y_pred_chains.mean(axis=0)\n",
    "\n",
    "temp = []\n",
    "org = []\n",
    "for i in range(len(predict_logisticregression_ensemble_ClassifierChain_Word2Vec)):\n",
    "    for j in range(len(predict_logisticregression_ensemble_ClassifierChain_Word2Vec[0])):\n",
    "        temp.append(int(predict_logisticregression_ensemble_ClassifierChain_Word2Vec[i][j]+0.8))\n",
    "    org.append(temp)\n",
    "    temp = []\n",
    "    \n",
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec = np.asarray(org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.CC at 0x7fbc16736cc0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = CC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "cc.fit(x_train,y_train)\n",
    "save_model(cc,'LogisticRegression_Word2Vec_CC.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_CC_ClassifierChain_Word2Vec=cc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.BR.BR at 0x7fbc146639e8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = BR(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "br.fit(x_train,y_train)\n",
    "save_model(br,'LogisticRegression_Word2Vec_BR.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_BR_ClassifierChain_Word2Vec=br.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.MCC at 0x7fbc16840198>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc = MCC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "mcc.fit(x_train,y_train)\n",
    "save_model(mcc,'LogisticRegression_Word2Vec_MCC.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_MCC_ClassifierChain_Word2Vec=mcc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.3 visualization and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec:  0.458769941443\n",
      "f1_score_prediction_logisticregression_pure_chain_Word2Vec:  0.495937437133\n",
      "f1_score_logisticregression_CC_ClassifierChain_Word2Vec:  0.465931111214\n",
      "f1_score_logisticregression_BR_ClassifierChain_Word2Vec:  0.458790223185\n",
      "f1_score_logisticregression_MCC_ClassifierChain_Word2Vec:  0.468526692773\n"
     ]
    }
   ],
   "source": [
    "f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec = f1_score(y_test,prediction_logisticregression_OneVsRestClassifier_Word2Vec,average='weighted')\n",
    "f1_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec = f1_score(y_test,predict_logisticregression_ensemble_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_logisticregression_CC_ClassifierChain_Word2Vec = f1_score(y_test,predict_logisticregression_CC_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_logisticregression_BR_ClassifierChain_Word2Vec = f1_score(y_test,predict_logisticregression_BR_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_logisticregression_MCC_ClassifierChain_Word2Vec = f1_score(y_test,predict_logisticregression_MCC_ClassifierChain_Word2Vec,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec: ',f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "print('f1_score_prediction_logisticregression_pure_chain_Word2Vec: ',f1_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec)\n",
    "print('f1_score_logisticregression_CC_ClassifierChain_Word2Vec: ',f1_score_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "print('f1_score_logisticregression_BR_ClassifierChain_Word2Vec: ',f1_score_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "print('f1_score_logisticregression_MCC_ClassifierChain_Word2Vec: ',f1_score_logisticregression_MCC_ClassifierChain_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec:  0.0633441558442\n",
      "Hamming_loss_prediction_logisticregression_pure_chain_Word2Vec:  0.0659686147186\n",
      "Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec:  0.0643019480519\n",
      "Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec:  0.063382034632\n",
      "Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec:  0.0641829004329\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec = Hamming_loss(y_test,prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "Hamming_loss_prediction_logisticregression_pure_ClassifierChain_Word2Vec = Hamming_loss(y_test,predict_logisticregression_ensemble_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec = Hamming_loss(y_test,predict_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec = Hamming_loss(y_test,predict_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec = Hamming_loss(y_test,predict_logisticregression_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec: ',Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "print('Hamming_loss_prediction_logisticregression_pure_chain_Word2Vec: ',Hamming_loss_prediction_logisticregression_pure_ClassifierChain_Word2Vec)\n",
    "print('Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec: ',Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "print('Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec: ',Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "print('Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec: ',Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec:  0.936655844156\n",
      "Hamming_score_prediction_logisticregression_pure_chain_Word2Vec:  0.934031385281\n",
      "Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec:  0.935698051948\n",
      "Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec:  0.936617965368\n",
      "Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec:  0.935817099567\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec = Hamming_score(y_test,prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "Hamming_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec = Hamming_score(y_test,predict_logisticregression_ensemble_ClassifierChain_Word2Vec)\n",
    "Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec = Hamming_score(y_test,predict_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec = Hamming_score(y_test,predict_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec = Hamming_score(y_test,predict_logisticregression_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec: ',Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "print('Hamming_score_prediction_logisticregression_pure_chain_Word2Vec: ',Hamming_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec)\n",
    "print('Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec: ',Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "print('Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec: ',Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "print('Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec: ',Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec:  0.160454545455\n",
      "Exact_match_prediction_logisticregression_pure_chain_Word2Vec:  0.17696969697\n",
      "Exact_match_logisticregression_CC_ClassifierChain_Word2Vec:  0.186666666667\n",
      "Exact_match_logisticregression_BR_ClassifierChain_Word2Vec:  0.161060606061\n",
      "Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec:  0.19303030303\n"
     ]
    }
   ],
   "source": [
    "Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec = Exact_match(y_test,prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "Exact_match_prediction_logisticregression_pure_ClassifierChain_Word2Vec = Exact_match(y_test,predict_logisticregression_ensemble_ClassifierChain_Word2Vec)\n",
    "Exact_match_logisticregression_CC_ClassifierChain_Word2Vec = Exact_match(y_test,predict_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "Exact_match_logisticregression_BR_ClassifierChain_Word2Vec = Exact_match(y_test,predict_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec = Exact_match(y_test,predict_logisticregression_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec: ',Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec)\n",
    "print('Exact_match_prediction_logisticregression_pure_chain_Word2Vec: ',Exact_match_prediction_logisticregression_pure_ClassifierChain_Word2Vec)\n",
    "print('Exact_match_logisticregression_CC_ClassifierChain_Word2Vec: ',Exact_match_logisticregression_CC_ClassifierChain_Word2Vec)\n",
    "print('Exact_match_logisticregression_BR_ClassifierChain_Word2Vec: ',Exact_match_logisticregression_BR_ClassifierChain_Word2Vec)\n",
    "print('Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec: ',Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier_Word2Vec = DecisionTreeClassifier(min_samples_split=2, random_state=1)\n",
    "DecisionTreeClassifier_Word2Vec.fit(x_train,y_train)\n",
    "save_model(DecisionTreeClassifier_Word2Vec,'DecisionTreeClassifier_Word2Vec.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_DecisionTreeClassifier_Word2Vec = DecisionTreeClassifier_Word2Vec.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_prediction_DecisionTreeClassifier_Word2Vec:  0.458769941443\n"
     ]
    }
   ],
   "source": [
    "f1_score_DecisionTreeClassifier_Word2Vec = f1_score(y_test,predict_DecisionTreeClassifier_Word2Vec,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_DecisionTreeClassifier_Word2Vec: ',f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_DecisionTreeClassifier_Word2Vec:  0.10987012987\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_DecisionTreeClassifier_Word2Vec = Hamming_loss(y_test,predict_DecisionTreeClassifier_Word2Vec)\n",
    "\n",
    "print('Hamming_loss_DecisionTreeClassifier_Word2Vec: ',Hamming_loss_DecisionTreeClassifier_Word2Vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_DecisionTreeClassifier_Word2Vec:  0.89012987013\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_DecisionTreeClassifier_Word2Vec = Hamming_score(y_test,predict_DecisionTreeClassifier_Word2Vec)\n",
    "\n",
    "print('Hamming_score_DecisionTreeClassifier_Word2Vec: ',Hamming_score_DecisionTreeClassifier_Word2Vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_DecisionTreeClassifier_Word2Vec:  0.0557575757576\n"
     ]
    }
   ],
   "source": [
    "Exact_match_DecisionTreeClassifier_Word2Vec = Exact_match(y_test,predict_DecisionTreeClassifier_Word2Vec)\n",
    "\n",
    "print('Exact_match_DecisionTreeClassifier_Word2Vec: ',Exact_match_DecisionTreeClassifier_Word2Vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.4.1 OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf \n",
      "[CV] clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf \n",
      "[CV]  clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf, score=0.0032835820895522386, total= 4.3min\n",
      "[CV]  clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf, score=0.003582089552238806, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=-1))]\n",
      "Applying best classifier on test data:\n",
      "grid_search_tune.best_estimator :  ('clf', OneVsRestClassifier(estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=-1))\n"
     ]
    }
   ],
   "source": [
    "clf_SVM_OneVsRestClassifier_Word2Vec = svm(x_train, x_test, y_train, y_test)\n",
    "prediction_SVM_OneVsRestClassifier_Word2Vec = clf_SVM_OneVsRestClassifier_Word2Vec.predict(x_test)\n",
    "save_model(clf_SVM_OneVsRestClassifier_Word2Vec,'SVM_OneVsRestClassifier_Word2Vec.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.4.2 ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=4)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=5)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=6)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=7)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=9)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains = [ClassifierChain(SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, shrinking=True,\n",
    "  tol=0.001, verbose=False), random_state=i)\n",
    "          for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_chains = np.array([chain.predict(x_test) for chain in\n",
    "                          chains])\n",
    "predict_svm_ensemble_ClassifierChain_Word2Vec = y_pred_chains.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "temp = []\n",
    "org = []\n",
    "for i in range(len(predict_svm_ensemble_ClassifierChain_Word2Vec)):\n",
    "    for j in range(len(predict_svm_ensemble_ClassifierChain_Word2Vec[0])):\n",
    "        temp.append(int(predict_svm_ensemble_ClassifierChain_Word2Vec[i][j]+0.8))\n",
    "    org.append(temp)\n",
    "    temp = []\n",
    "    \n",
    "predict_svm_ensemble_ClassifierChain_Word2Vec = np.asarray(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.CC at 0x7fbc146202e8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = CC(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "cc.fit(x_train,y_train)\n",
    "save_model(cc,'SVM_Chain_CC_Word2Vec.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.BR.BR at 0x7fbc16737f60>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = BR(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "br.fit(x_train,y_train)\n",
    "save_model(br,'SVM_Chain_BR_Word2Vec.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MCC(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "mcc.fit(x_train,y_train)\n",
    "save_model(mcc,'SVM_Chain_MCC_Word2Vec.sav','Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_svm_CC_ClassifierChain_Word2Vec=cc.predict(x_test)\n",
    "predict_svm_BR_ClassifierChain_Word2Vec=br.predict(x_test)\n",
    "predict_svm_MCC_ClassifierChain_Word2Vec=mcc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score_svm_OnevsResClassifier_svm_Word2Vec = f1_score(y_test,prediction_SVM_OneVsRestClassifier_Word2Vec,average='weighted')\n",
    "f1_score_svm_pure_chain_svm_Word2Vec = f1_score(y_test,predict_svm_ensemble_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_svm_CC_svm_Word2Vec = f1_score(y_test,predict_svm_CC_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_svm_BR_svm_Word2Vec = f1_score(y_test,predict_svm_BR_ClassifierChain_Word2Vec,average='weighted')\n",
    "f1_score_svm_MCC_svm_Word2Vec = f1_score(y_test,predict_svm_MCC_ClassifierChain_Word2Vec,average='weighted')\n",
    "\n",
    "print('f1_score_svm_OnevsResClassifier_svm_Word2Vec: ',f1_score_svm_OnevsResClassifier_svm_Word2Vec)\n",
    "print('f1_score_svm_pure_chain_svm_Word2Vec: ',f1_score_svm_pure_chain_svm_Word2Vec)\n",
    "print('f1_score_svm_CC_ClassifierChain_Word2Vec: ',f1_score_svm_CC_svm_Word2Vec)\n",
    "print('f1_score_svm_BR_ClassifierChain_Word2Vec: ',f1_score_svm_BR_svm_Word2Vec)\n",
    "print('f1_score_svm_MCC_ClassifierChain_Word2Vec: ',f1_score_svm_MCC_svm_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec = Hamming_loss(y_test,prediction_SVM_OneVsRestClassifier_Word2Vec)\n",
    "Hamming_loss_svm_pure_chain_svm_Word2Vec = Hamming_loss(y_test,predict_svm_ensemble_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_svm_CC_svm_Word2Vec = Hamming_loss(y_test,predict_svm_CC_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_svm_BR_svm_Word2Vec = Hamming_loss(y_test,predict_svm_BR_ClassifierChain_Word2Vec)\n",
    "Hamming_loss_svm_MCC_svm_Word2Vec = Hamming_loss(y_test,predict_svm_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec: ',Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec)\n",
    "print('Hamming_loss_svm_pure_chain_svm_Word2Vec: ',Hamming_loss_svm_pure_chain_svm_Word2Vec)\n",
    "print('Hamming_loss_svm_CC_ClassifierChain_Word2Vec: ',Hamming_loss_svm_CC_svm_Word2Vec)\n",
    "print('Hamming_loss_svm_BR_ClassifierChain_Word2Vec: ',Hamming_loss_svm_BR_svm_Word2Vec)\n",
    "print('Hamming_loss_svm_MCC_ClassifierChain_Word2Vec: ',Hamming_loss_svm_MCC_svm_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hamming_score_svm_OnevsResClassifier_svm_Word2Vec = Hamming_score(y_test,prediction_SVM_OneVsRestClassifier_Word2Vec)\n",
    "Hamming_score_svm_pure_chain_svm_Word2Vec = Hamming_score(y_test,predict_svm_ensemble_ClassifierChain_Word2Vec)\n",
    "Hamming_score_svm_CC_svm_Word2Vec = Hamming_score(y_test,predict_svm_CC_ClassifierChain_Word2Vec)\n",
    "Hamming_score_svm_BR_svm_Word2Vec = Hamming_score(y_test,predict_svm_BR_ClassifierChain_Word2Vec)\n",
    "Hamming_score_svm_MCC_svm_Word2Vec = Hamming_score(y_test,predict_svm_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Hamming_score_svm_OnevsResClassifier_svm_Word2Vec: ',Hamming_score_svm_OnevsResClassifier_svm_Word2Vec)\n",
    "print('Hamming_score_svm_pure_chain_svm_Word2Vec: ',Hamming_score_svm_pure_chain_svm_Word2Vec)\n",
    "print('Hamming_score_svm_CC_ClassifierChain_Word2Vec: ',Hamming_score_svm_CC_svm_Word2Vec)\n",
    "print('Hamming_score_svm_BR_ClassifierChain_Word2Vec: ',Hamming_score_svm_BR_svm_Word2Vec)\n",
    "print('Hamming_score_svm_MCC_ClassifierChain_Word2Vec: ',Hamming_score_svm_MCC_svm_Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Exact_match_svm_OnevsResClassifier_svm_Word2Vec = Exact_match(y_test,prediction_SVM_OneVsRestClassifier_Word2Vec)\n",
    "Exact_match_svm_pure_chain_svm_Word2Vec = Exact_match(y_test,predict_svm_ensemble_ClassifierChain_Word2Vec)\n",
    "Exact_match_svm_CC_svm_Word2Vec = Exact_match(y_test,predict_svm_CC_ClassifierChain_Word2Vec)\n",
    "Exact_match_svm_BR_svm_Word2Vec = Exact_match(y_test,predict_svm_BR_ClassifierChain_Word2Vec)\n",
    "Exact_match_svm_MCC_svm_Word2Vec = Exact_match(y_test,predict_svm_MCC_ClassifierChain_Word2Vec)\n",
    "\n",
    "print('Exact_match_svm_OnevsResClassifier_svm_Word2Vec: ',Exact_match_svm_OnevsResClassifier_svm_Word2Vec)\n",
    "print('Exact_match_svm_pure_chain_svm_Word2Vec: ',Exact_match_svm_pure_chain_svm_Word2Vec)\n",
    "print('Exact_match_svm_CC_ClassifierChain_Word2Vec: ',Exact_match_svm_CC_svm_Word2Vec)\n",
    "print('Exact_match_svm_BR_ClassifierChain_Word2Vec: ',Exact_match_svm_BR_svm_Word2Vec)\n",
    "print('Exact_match_svm_MCC_ClassifierChain_Word2Vec: ',Exact_match_svm_MCC_svm_Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Word2Vec_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading The data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data_10 shape:  (200000, 300)\n",
      "y_data_10 shape:  (200000, 28)\n"
     ]
    }
   ],
   "source": [
    "x_data_10 = pd.read_csv('/home/sina/input/word2vec_10/x_embeddings_Word2Vec_top10.csv')\n",
    "y_data_10 = pd.read_csv('/home/sina/input/word2vec_10/y_data_Word2Vec_top10.csv')\n",
    "x_data_10 = x_data_10.as_matrix()\n",
    "y_data_10 = y_data_10.as_matrix()\n",
    "x_data_10 = x_data_10[0:200000]\n",
    "y_data_10 = y_data_10[0:200000]\n",
    "print('x_data_10 shape: ', x_data_10.shape)\n",
    "print('y_data_10 shape: ', y_data_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data_10 = np.delete(y_data_10,22,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Split data to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_data_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_10, x_test_10, y_train_10, y_test_10 = train_test_split(x_data_10, y_data_10, test_size=0.33, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 shape of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_10 shape:  (134000, 300)\n",
      "y_train_10 shape:  (134000, 27)\n",
      "x_test_10 shape:  (66000, 300)\n",
      "y_test_10 shape:  (66000, 27)\n"
     ]
    }
   ],
   "source": [
    "print('x_train_10 shape: ', x_train_10.shape)\n",
    "print('y_train_10 shape: ', y_train_10.shape)\n",
    "print('x_test_10 shape: ', x_test_10.shape)\n",
    "print('y_test_10 shape: ', y_test_10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 apply different algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1.1 OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.05925373134328358, total=   9.6s\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.0635820895522388, total=   9.8s\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   6 | elapsed:   10.0s remaining:   20.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.19850746268656716, total=  12.4s\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   6 | elapsed:   12.8s remaining:   12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.19298507462686568, total=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   4 out of   6 | elapsed:   22.3s remaining:   11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.24223880597014924, total=  35.7s\n",
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.24865671641791046, total=  44.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:   54.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:   54.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))]\n",
      "Applying best classifier on test data:\n",
      "grid_search_tune.best_estimator :  ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))\n"
     ]
    }
   ],
   "source": [
    "bst_clf_logisticregression_OneVsRestClassifier_Word2Vec_10=logisticRegression(x_train_10, x_test_10, y_train_10, y_test_10)\n",
    "save_model(bst_clf_logisticregression_OneVsRestClassifier_Word2Vec_10,'logisticregression_OneVsRestClassifier_Word2Vec_10.sav','Word2Vec_10')\n",
    "prediction_logisticregression_OneVsRestClassifier_Word2Vec_10 = bst_clf_logisticregression_OneVsRestClassifier_Word2Vec_10.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1.2 ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        cv=None, order='random', random_state=9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains = [ClassifierChain(LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False), order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "i=0\n",
    "for chain in chains:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    chain.fit(x_train_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_chains = np.array([chain.predict(x_test_10) for chain in\n",
    "                          chains])\n",
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10 = y_pred_chains.mean(axis=0)\n",
    "\n",
    "temp = []\n",
    "org = []\n",
    "for i in range(len(predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10)):\n",
    "    for j in range(len(predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10[0])):\n",
    "        temp.append(int(predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10[i][j]+0.8))\n",
    "    org.append(temp)\n",
    "    temp = []\n",
    "    \n",
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10 = np.asarray(org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.CC at 0x7fc05b384b38>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = CC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "cc.fit(x_train_10,y_train_10)\n",
    "save_model(cc,'LogisticRegression_Word2Vec_CC_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_CC_ClassifierChain_Word2Vec_10=cc.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.BR.BR at 0x7fc05b610a20>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = BR(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "br.fit(x_train_10,y_train_10)\n",
    "save_model(br,'LogisticRegression_Word2Vec_BR_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_BR_ClassifierChain_Word2Vec_10=br.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.MCC at 0x7fc0581d2198>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc = MCC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "mcc.fit(x_train_10,y_train_10)\n",
    "save_model(mcc,'LogisticRegression_Word2Vec_MCC.sav_10','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_MCC_ClassifierChain_Word2Vec_10=mcc.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1.3 visualization and scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6600, 27)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6600, 27)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10:  0.436735826424\n",
      "f1_score_prediction_logisticregression_pure_chain_Word2Vec_10:  0.499217589218\n",
      "f1_score_logisticregression_CC_ClassifierChain_Word2Vec_10:  0.464418432692\n",
      "f1_score_logisticregression_BR_ClassifierChain_Word2Vec_10:  0.43704132753\n",
      "f1_score_logisticregression_MCC_ClassifierChain_Word2Vec_10:  0.492505577493\n"
     ]
    }
   ],
   "source": [
    "f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10 = f1_score(y_test_10,prediction_logisticregression_OneVsRestClassifier_Word2Vec_10,average='weighted')\n",
    "f1_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10 = f1_score(y_test_10,predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_logisticregression_CC_ClassifierChain_Word2Vec_10 = f1_score(y_test_10,predict_logisticregression_CC_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_logisticregression_BR_ClassifierChain_Word2Vec_10 = f1_score(y_test_10,predict_logisticregression_BR_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_logisticregression_MCC_ClassifierChain_Word2Vec_10 = f1_score(y_test_10,predict_logisticregression_MCC_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10: ',f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "print('f1_score_prediction_logisticregression_pure_chain_Word2Vec_10: ',f1_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10)\n",
    "print('f1_score_logisticregression_CC_ClassifierChain_Word2Vec_10: ',f1_score_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "print('f1_score_logisticregression_BR_ClassifierChain_Word2Vec_10: ',f1_score_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "print('f1_score_logisticregression_MCC_ClassifierChain_Word2Vec_10: ',f1_score_logisticregression_MCC_ClassifierChain_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10:  0.0396801346801\n",
      "Hamming_loss_prediction_logisticregression_pure_chain_Word2Vec_10:  0.0516722783389\n",
      "Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec_10:  0.0445230078563\n",
      "Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec_10:  0.0396240179574\n",
      "Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec_10:  0.0420145903479\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10 = Hamming_loss(y_test_10,prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "Hamming_loss_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10 = Hamming_loss(y_test_10,predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec_10 = Hamming_loss(y_test_10,predict_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec_10 = Hamming_loss(y_test_10,predict_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec_10 = Hamming_loss(y_test_10,predict_logisticregression_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10: ',Hamming_loss_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "print('Hamming_loss_prediction_logisticregression_pure_chain_Word2Vec_10: ',Hamming_loss_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec_10: ',Hamming_loss_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec_10: ',Hamming_loss_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec_10: ',Hamming_loss_logisticregression_MCC_ClassifierChain_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10:  0.96031986532\n",
      "Hamming_score_prediction_logisticregression_pure_chain_Word2Vec_10:  0.948327721661\n",
      "Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec_10:  0.955476992144\n",
      "Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec_10:  0.960375982043\n",
      "Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec_10:  0.957985409652\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10 = Hamming_score(y_test_10,prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "Hamming_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10 = Hamming_score(y_test_10,predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec_10 = Hamming_score(y_test_10,predict_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec_10 = Hamming_score(y_test_10,predict_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec_10 = Hamming_score(y_test_10,predict_logisticregression_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10: ',Hamming_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "print('Hamming_score_prediction_logisticregression_pure_chain_Word2Vec_10: ',Hamming_score_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec_10: ',Hamming_score_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec_10: ',Hamming_score_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "print('Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec_10: ',Hamming_score_logisticregression_MCC_ClassifierChain_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10:  0.263181818182\n",
      "Exact_match_prediction_logisticregression_pure_chain_Word2Vec_10:  0.287575757576\n",
      "Exact_match_logisticregression_CC_ClassifierChain_Word2Vec_10:  0.34696969697\n",
      "Exact_match_logisticregression_BR_ClassifierChain_Word2Vec_10:  0.263939393939\n",
      "Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec_10:  0.385151515152\n"
     ]
    }
   ],
   "source": [
    "Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10 = Exact_match(y_test_10,prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "Exact_match_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10 = Exact_match(y_test_10,predict_logisticregression_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_logisticregression_CC_ClassifierChain_Word2Vec_10 = Exact_match(y_test_10,predict_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_logisticregression_BR_ClassifierChain_Word2Vec_10 = Exact_match(y_test_10,predict_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec_10 = Exact_match(y_test_10,predict_logisticregression_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10: ',Exact_match_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)\n",
    "print('Exact_match_prediction_logisticregression_pure_chain_Word2Vec_10: ',Exact_match_prediction_logisticregression_pure_ClassifierChain_Word2Vec_10)\n",
    "print('Exact_match_logisticregression_CC_ClassifierChain_Word2Vec_10: ',Exact_match_logisticregression_CC_ClassifierChain_Word2Vec_10)\n",
    "print('Exact_match_logisticregression_BR_ClassifierChain_Word2Vec_10: ',Exact_match_logisticregression_BR_ClassifierChain_Word2Vec_10)\n",
    "print('Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec_10: ',Exact_match_logisticregression_MCC_ClassifierChain_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier_Word2Vec_10 = DecisionTreeClassifier(min_samples_split=2, random_state=1)\n",
    "DecisionTreeClassifier_Word2Vec_10.fit(x_train_10,y_train_10)\n",
    "save_model(DecisionTreeClassifier_Word2Vec_10,'DecisionTreeClassifier_Word2Vec_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_DecisionTreeClassifier_Word2Vec_10 = DecisionTreeClassifier_Word2Vec_10.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_prediction_DecisionTreeClassifier_Word2Vec_10:  0.436735826424\n"
     ]
    }
   ],
   "source": [
    "f1_score_DecisionTreeClassifier_Word2Vec_10 = f1_score(y_test_10,predict_DecisionTreeClassifier_Word2Vec_10,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_DecisionTreeClassifier_Word2Vec_10: ',f1_score_prediction_logisticregression_OneVsRestClassifier_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_DecisionTreeClassifier_Word2Vec_10:  0.0708136924804\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_DecisionTreeClassifier_Word2Vec_10 = Hamming_loss(y_test_10,predict_DecisionTreeClassifier_Word2Vec_10)\n",
    "\n",
    "print('Hamming_loss_DecisionTreeClassifier_Word2Vec_10: ',Hamming_loss_DecisionTreeClassifier_Word2Vec_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_DecisionTreeClassifier_Word2Vec_10:  0.92918630752\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_DecisionTreeClassifier_Word2Vec_10 = Hamming_score(y_test_10,predict_DecisionTreeClassifier_Word2Vec_10)\n",
    "\n",
    "print('Hamming_score_DecisionTreeClassifier_Word2Vec_10: ',Hamming_score_DecisionTreeClassifier_Word2Vec_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_DecisionTreeClassifier_Word2Vec_10:  0.154242424242\n"
     ]
    }
   ],
   "source": [
    "Exact_match_DecisionTreeClassifier_Word2Vec_10 = Exact_match(y_test_10,predict_DecisionTreeClassifier_Word2Vec_10)\n",
    "\n",
    "print('Exact_match_DecisionTreeClassifier_Word2Vec_10: ',Exact_match_DecisionTreeClassifier_Word2Vec_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.4.1 OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf \n",
      "[CV] clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf \n",
      "[CV]  clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf, score=0.0, total= 2.7min\n",
      "[CV]  clf__estimator__C=10, clf__estimator__gamma=0.001, clf__estimator__kernel=rbf, score=0.0, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=-1))]\n",
      "Applying best classifier on test data:\n",
      "grid_search_tune.best_estimator :  ('clf', OneVsRestClassifier(estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "          n_jobs=-1))\n"
     ]
    }
   ],
   "source": [
    "clf_SVM_OneVsRestClassifier_Word2Vec_10 = svm(x_train_10, x_test_10, y_train_10, y_test_10)\n",
    "prediction_SVM_OneVsRestClassifier_Word2Vec_10 = clf_SVM_OneVsRestClassifier_Word2Vec_10.predict(x_test_10)\n",
    "save_model(clf_SVM_OneVsRestClassifier_Word2Vec_10,'SVM_OneVsRestClassifier_Word2Vec_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4.2 ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(base_estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        cv=None, order=None, random_state=9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains = [ClassifierChain(SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, shrinking=True,\n",
    "  tol=0.001, verbose=False), random_state=i)\n",
    "          for i in range(10)]\n",
    "i=0\n",
    "for chain in chains:\n",
    "    print(i+1)\n",
    "    i+=1\n",
    "    chain.fit(x_train_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_chains = np.array([chain.predict(x_test_10) for chain in\n",
    "                          chains])\n",
    "predict_svm_ensemble_ClassifierChain_Word2Vec_10 = y_pred_chains.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "temp = []\n",
    "org = []\n",
    "for i in range(len(predict_svm_ensemble_ClassifierChain_Word2Vec_10)):\n",
    "    for j in range(len(predict_svm_ensemble_ClassifierChain_Word2Vec_10[0])):\n",
    "        temp.append(int(predict_svm_ensemble_ClassifierChain_Word2Vec_10[i][j]+0.8))\n",
    "    org.append(temp)\n",
    "    temp = []\n",
    "    \n",
    "predict_svm_ensemble_ClassifierChain_Word2Vec_10 = np.asarray(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.CC at 0x7fbc167c9f98>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = CC(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "cc.fit(x_train_10,y_train_10)\n",
    "save_model(cc,'SVM_Chain_CC_Word2Vec_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.BR.BR at 0x7fbc14663400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = BR(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "br.fit(x_train_10,y_train_10)\n",
    "save_model(br,'SVM_Chain_BR_Word2Vec_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molearn.classifiers.classifier_chains.MCC at 0x7fbc146637b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc = MCC(h=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, shrinking=True,\n",
    "  tol=0.001, verbose=False))\n",
    "mcc.fit(x_train_10,y_train_10)\n",
    "save_model(mcc,'SVM_Chain_MCC_Word2Vec_10.sav','Word2Vec_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_svm_CC_ClassifierChain_Word2Vec_10=cc.predict(x_test_10)\n",
    "predict_svm_BR_ClassifierChain_Word2Vec_10=br.predict(x_test_10)\n",
    "predict_svm_MCC_ClassifierChain_Word2Vec_10=mcc.predict(x_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.4.3 Scores and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_svm_OnevsResClassifier_svm_Word2Vec_10:  0.000703726705372\n",
      "f1_score_svm_pure_chain_svm_Word2Vec_10:  0.0772531980456\n",
      "f1_score_svm_CC_ClassifierChain_Word2Vec_10:  0.0772531980456\n",
      "f1_score_svm_BR_ClassifierChain_Word2Vec_10:  0.000703726705372\n",
      "f1_score_svm_MCC_ClassifierChain_Word2Vec_10:  0.440253558291\n"
     ]
    }
   ],
   "source": [
    "f1_score_svm_OnevsResClassifier_svm_Word2Vec_10 = f1_score(y_test_10,prediction_SVM_OneVsRestClassifier_Word2Vec_10,average='weighted')\n",
    "f1_score_svm_pure_chain_svm_Word2Vec_10 = f1_score(y_test_10,predict_svm_ensemble_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_svm_CC_svm_Word2Vec_10 = f1_score(y_test_10,predict_svm_CC_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_svm_BR_svm_Word2Vec_10 = f1_score(y_test_10,predict_svm_BR_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "f1_score_svm_MCC_svm_Word2Vec_10 = f1_score(y_test_10,predict_svm_MCC_ClassifierChain_Word2Vec_10,average='weighted')\n",
    "\n",
    "print('f1_score_svm_OnevsResClassifier_svm_Word2Vec_10: ',f1_score_svm_OnevsResClassifier_svm_Word2Vec_10)\n",
    "print('f1_score_svm_pure_chain_svm_Word2Vec_10: ',f1_score_svm_pure_chain_svm_Word2Vec_10)\n",
    "print('f1_score_svm_CC_ClassifierChain_Word2Vec_10: ',f1_score_svm_CC_svm_Word2Vec_10)\n",
    "print('f1_score_svm_BR_ClassifierChain_Word2Vec_10: ',f1_score_svm_BR_svm_Word2Vec_10)\n",
    "print('f1_score_svm_MCC_ClassifierChain_Word2Vec_10: ',f1_score_svm_MCC_svm_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec_10:  0.0477441077441\n",
      "Hamming_loss_svm_pure_chain_svm_Word2Vec_10:  0.0466947250281\n",
      "Hamming_loss_svm_CC_ClassifierChain_Word2Vec_10:  0.0466947250281\n",
      "Hamming_loss_svm_BR_ClassifierChain_Word2Vec_10:  0.0477441077441\n",
      "Hamming_loss_svm_MCC_ClassifierChain_Word2Vec_10:  0.0442368125701\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec_10 = Hamming_loss(y_test_10,prediction_SVM_OneVsRestClassifier_Word2Vec_10)\n",
    "Hamming_loss_svm_pure_chain_svm_Word2Vec_10 = Hamming_loss(y_test_10,predict_svm_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_svm_CC_svm_Word2Vec_10 = Hamming_loss(y_test_10,predict_svm_CC_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_svm_BR_svm_Word2Vec_10 = Hamming_loss(y_test_10,predict_svm_BR_ClassifierChain_Word2Vec_10)\n",
    "Hamming_loss_svm_MCC_svm_Word2Vec_10 = Hamming_loss(y_test_10,predict_svm_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec_10: ',Hamming_loss_svm_OnevsResClassifier_svm_Word2Vec_10)\n",
    "print('Hamming_loss_svm_pure_chain_svm_Word2Vec_10: ',Hamming_loss_svm_pure_chain_svm_Word2Vec_10)\n",
    "print('Hamming_loss_svm_CC_ClassifierChain_Word2Vec_10: ',Hamming_loss_svm_CC_svm_Word2Vec_10)\n",
    "print('Hamming_loss_svm_BR_ClassifierChain_Word2Vec_10: ',Hamming_loss_svm_BR_svm_Word2Vec_10)\n",
    "print('Hamming_loss_svm_MCC_ClassifierChain_Word2Vec_10: ',Hamming_loss_svm_MCC_svm_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_svm_OnevsResClassifier_svm_Word2Vec_10:  0.952255892256\n",
      "Hamming_score_svm_pure_chain_svm_Word2Vec_10:  0.953305274972\n",
      "Hamming_score_svm_CC_ClassifierChain_Word2Vec_10:  0.953305274972\n",
      "Hamming_score_svm_BR_ClassifierChain_Word2Vec_10:  0.952255892256\n",
      "Hamming_score_svm_MCC_ClassifierChain_Word2Vec_10:  0.95576318743\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_svm_OnevsResClassifier_svm_Word2Vec_10 = Hamming_score(y_test_10,prediction_SVM_OneVsRestClassifier_Word2Vec_10)\n",
    "Hamming_score_svm_pure_chain_svm_Word2Vec_10 = Hamming_score(y_test_10,predict_svm_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_svm_CC_svm_Word2Vec_10 = Hamming_score(y_test_10,predict_svm_CC_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_svm_BR_svm_Word2Vec_10 = Hamming_score(y_test_10,predict_svm_BR_ClassifierChain_Word2Vec_10)\n",
    "Hamming_score_svm_MCC_svm_Word2Vec_10 = Hamming_score(y_test_10,predict_svm_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Hamming_score_svm_OnevsResClassifier_svm_Word2Vec_10: ',Hamming_score_svm_OnevsResClassifier_svm_Word2Vec_10)\n",
    "print('Hamming_score_svm_pure_chain_svm_Word2Vec_10: ',Hamming_score_svm_pure_chain_svm_Word2Vec_10)\n",
    "print('Hamming_score_svm_CC_ClassifierChain_Word2Vec_10: ',Hamming_score_svm_CC_svm_Word2Vec_10)\n",
    "print('Hamming_score_svm_BR_ClassifierChain_Word2Vec_10: ',Hamming_score_svm_BR_svm_Word2Vec_10)\n",
    "print('Hamming_score_svm_MCC_ClassifierChain_Word2Vec_10: ',Hamming_score_svm_MCC_svm_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_svm_OnevsResClassifier_svm_Word2Vec_10:  0.000454545454545\n",
      "Exact_match_svm_pure_chain_svm_Word2Vec_10:  0.0463636363636\n",
      "Exact_match_svm_CC_ClassifierChain_Word2Vec_10:  0.0463636363636\n",
      "Exact_match_svm_BR_ClassifierChain_Word2Vec_10:  0.000454545454545\n",
      "Exact_match_svm_MCC_ClassifierChain_Word2Vec_10:  0.365606060606\n"
     ]
    }
   ],
   "source": [
    "Exact_match_svm_OnevsResClassifier_svm_Word2Vec_10 = Exact_match(y_test_10,prediction_SVM_OneVsRestClassifier_Word2Vec_10)\n",
    "Exact_match_svm_pure_chain_svm_Word2Vec_10 = Exact_match(y_test_10,predict_svm_ensemble_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_svm_CC_svm_Word2Vec_10 = Exact_match(y_test_10,predict_svm_CC_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_svm_BR_svm_Word2Vec_10 = Exact_match(y_test_10,predict_svm_BR_ClassifierChain_Word2Vec_10)\n",
    "Exact_match_svm_MCC_svm_Word2Vec_10 = Exact_match(y_test_10,predict_svm_MCC_ClassifierChain_Word2Vec_10)\n",
    "\n",
    "print('Exact_match_svm_OnevsResClassifier_svm_Word2Vec_10: ',Exact_match_svm_OnevsResClassifier_svm_Word2Vec_10)\n",
    "print('Exact_match_svm_pure_chain_svm_Word2Vec_10: ',Exact_match_svm_pure_chain_svm_Word2Vec_10)\n",
    "print('Exact_match_svm_CC_ClassifierChain_Word2Vec_10: ',Exact_match_svm_CC_svm_Word2Vec_10)\n",
    "print('Exact_match_svm_BR_ClassifierChain_Word2Vec_10: ',Exact_match_svm_BR_svm_Word2Vec_10)\n",
    "print('Exact_match_svm_MCC_ClassifierChain_Word2Vec_10: ',Exact_match_svm_MCC_svm_Word2Vec_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.4.5 bp_mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train_10.shape[0]\n",
    "dim_no = x_train_10.shape[1]\n",
    "class_no = y_train_10.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 170us/step - loss: 21.0852\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 2s 163us/step - loss: 20.3376\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 19.7188\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 19.3751\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 2s 191us/step - loss: 19.1146\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 2s 198us/step - loss: 18.9425\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 18.8747\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 2s 204us/step - loss: 18.7814\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 2s 203us/step - loss: 18.7363\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 2s 202us/step - loss: 18.6884\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 18.6517\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 2s 198us/step - loss: 18.6192\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 18.5587\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 2s 210us/step - loss: 18.5564\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 2s 195us/step - loss: 18.5252\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 2s 191us/step - loss: 18.5008\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 2s 198us/step - loss: 18.4779\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 18.4331\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 18.4177\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 2s 175us/step - loss: 18.3649\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 2s 173us/step - loss: 18.3369\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 18.3116\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 18.2687\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 2s 194us/step - loss: 18.2551\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 18.1989\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 2s 190us/step - loss: 18.2284\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 2s 193us/step - loss: 18.2017\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 18.1480\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 18.1131\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 18.0777\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 18.0710\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 2s 194us/step - loss: 18.0575\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 18.0342\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 18.0405\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 18.0166\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 18.0247\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 2s 193us/step - loss: 17.9703\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 2s 194us/step - loss: 17.9813\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 17.9373\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 2s 196us/step - loss: 17.9101\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 17.9434\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 17.9003\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 17.8958\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 2s 202us/step - loss: 17.9219\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 17.8793\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 17.8884\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 17.8533\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 2s 190us/step - loss: 17.8337\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 2s 189us/step - loss: 17.8301\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 2s 199us/step - loss: 17.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f210042a630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=dim_no, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(class_no, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "model.compile(loss=bp_mll_loss, optimizer='adagrad', metrics=[])\n",
    "\n",
    "\n",
    "model.fit(x_train_10, y_train_10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP-MLL F1-Score:  0.42315564035541475\n",
      "\n",
      "BP-MLL Hamming_loss:  0.10385185185185175\n",
      "\n",
      "BP-MLL Hamming_score:  0.8961481481481482\n",
      "\n",
      "BP-MLL Exact_match:  0.09\n"
     ]
    }
   ],
   "source": [
    "bpmll_Word2Vec = model.predict(x_test_10)\n",
    "\n",
    "\n",
    "res = []\n",
    "tmp = []\n",
    "\n",
    "for j in range(bpmll_Word2Vec.shape[0]):\n",
    "    for i in range(bpmll_Word2Vec.shape[1]):\n",
    "        tmp.append(int(bpmll_Word2Vec[j][i]+0.01))\n",
    "    res.append(tmp)\n",
    "    tmp = []\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "res = res.as_matrix()\n",
    "\n",
    "\n",
    "print('BP-MLL F1-Score: ',f1_score(y_test_10, res,average='weighted'))\n",
    "print('BP-MLL Hamming_loss: ',Hamming_loss(y_test_10, res))\n",
    "print('BP-MLL Hamming_score: ',Hamming_score(y_test_10, res))\n",
    "print('BP-MLL Exact_match: ',Exact_match(y_test_10, res))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
