{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is for training different ML models on TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from molearn.classifiers.BR import BR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from molearn.classifiers.Ensemble import Ensemble\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from molearn.classifiers.classifier_chains import CC,RCC,MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Hamming_loss(Ytest,Ypred):\n",
    "    ''' Hamming loss aka Hamming distance '''\n",
    "    return 1.-Hamming_score(Ytest,Ypred)\n",
    "\n",
    "def Hamming_score(Ytest,Ypred):\n",
    "    ''' Hamming score aka Hamming match '''\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum((Ytest == Ypred) * 1.) / N_test / L\n",
    "\n",
    "def Hamming_matches(Ytest,Ypred):\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum((Ytest == Ypred) * 1.,axis=0) / N_test \n",
    "\n",
    "def Hamming_losses(Ytest,Ypred):\n",
    "    return 1.-Hamming_matches(Ytest,Ypred)\n",
    "\n",
    "def Exact_match(Ytest,Ypred):\n",
    "    N_test,L = Ytest.shape\n",
    "    return np.sum(np.sum((Ytest == Ypred) * 1,axis=1)==L) * 1. / N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(train_x, train_y, test_x, test_y, parameters, pipeline):\n",
    "    grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=10)\n",
    "    grid_search_tune.fit(train_x, train_y)\n",
    "\n",
    "    print\n",
    "    print(\"Best parameters set:\")\n",
    "    print (grid_search_tune.best_estimator_.steps)\n",
    "    print\n",
    "\n",
    "    # measuring performance on test set\n",
    "    print (\"Applying best classifier on test data:\")\n",
    "    best_clf = grid_search_tune.best_estimator_\n",
    "    \n",
    "    predictions = best_clf.predict(test_x)\n",
    "    print('grid_search_tune.best_estimator : ',grid_search_tune.best_estimator_.steps[0])\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "def save_model(clf,filename,folder):\n",
    "    pickle.dump(clf, open(\"../trained-model/\"+folder+\"/\"+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        \"clf__estimator__C\": [0.1,1,10],\n",
    "        \"clf__estimator__class_weight\": [None],\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaboost(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    algorithm=\"SAMME\"), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        \"clf__estimator__learning_rate\": [1,1.5],\n",
    "        \"clf__estimator__n_estimators\": [6],\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naivebayes(x_train, x_test, y_train, y_test):\n",
    "        \n",
    "    print (\"LogisticRegression\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None), n_jobs=-1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "    }\n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "\n",
    "\n",
    "    print (\"LinearSVC\")\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(SVC(), n_jobs=-1)),\n",
    "    ])\n",
    "    \n",
    "    parameters ={\n",
    "         'clf__estimator__kernel': ['rbf'],\n",
    "         'clf__estimator__gamma': [1e-3],\n",
    "         'clf__estimator__C': [10]\n",
    "        }\n",
    "        \n",
    "    clf = grid_search(x_train, y_train, x_test, y_test, parameters, pipeline)    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.TF-IDF(bag-of-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../vectors/all/tfidf/x_data_train_tfidf.csv')\n",
    "y_train = pd.read_csv('../vectors/all/tfidf/y_data_train_tfidf.csv')\n",
    "x_test = pd.read_csv('../vectors/all/tfidf/x_data_test_tfidf.csv')\n",
    "y_test = pd.read_csv('../vectors/all/tfidf/y_data_test_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = shuffle(x_train.as_matrix())\n",
    "y_train = shuffle(y_train.as_matrix())\n",
    "x_test = shuffle(x_test.as_matrix())\n",
    "y_test = shuffle(y_test.as_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (600, 51053)\n",
      "y_train shape:  (600, 28)\n",
      "x_test shape:  (100, 51053)\n",
      "y_test shape:  (100, 28)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[0:600]\n",
    "y_train = y_train[0:600]\n",
    "x_test = x_test[0:100]\n",
    "y_test = y_test[0:100]\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 shape of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (600, 51053)\n",
      "y_train shape:  (600, 28)\n",
      "x_test shape:  (100, 51053)\n",
      "y_test shape:  (100, 28)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 apply different algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.1 OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=0.1, clf__estimator__class_weight=None ........\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=None ..........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.0, total= 3.4min\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n",
      "[CV]  clf__estimator__C=0.1, clf__estimator__class_weight=None, score=0.0, total= 3.5min\n",
      "[CV] clf__estimator__C=10, clf__estimator__class_weight=None .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   6 | elapsed:  3.5min remaining:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.0, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  3.6min remaining:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=None, score=0.0, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:  3.6min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.0033333333333333335, total= 3.1min\n",
      "[CV]  clf__estimator__C=10, clf__estimator__class_weight=None, score=0.016666666666666666, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))]\n",
      "Applying best classifier on test data:\n",
      "grid_search_tune.best_estimator :  ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          n_jobs=-1))\n"
     ]
    }
   ],
   "source": [
    "bst_clf_logisticregression_OneVsRestClassifier_tfidf=logisticRegression(x_train, x_test, y_train, y_test)\n",
    "save_model(bst_clf_logisticregression_OneVsRestClassifier_tfidf,'logisticregression_OneVsRestClassifier_tfidf.sav','tfidf')\n",
    "prediction_logisticregression_OneVsRestClassifier_tfidf = bst_clf_logisticregression_OneVsRestClassifier_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.2 ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = [ClassifierChain(LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False), order='random', random_state=i)\n",
    "          for i in range(1)]\n",
    "\n",
    "for idx,chain in enumerate(chains):\n",
    "    if idx%4==0 or idx==10:\n",
    "        print(idx,\"chain\")\n",
    "    chain.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_chains = np.array([chain.predict(x_test) for chain in\n",
    "                          chains])\n",
    "predict_logisticregression_ensemble_ClassifierChain_tfidf = y_pred_chains.mean(axis=0)\n",
    "\n",
    "temp = []\n",
    "org = []\n",
    "for i in range(len(predict_logisticregression_ensemble_ClassifierChain_tfidf)):\n",
    "    for j in range(len(predict_logisticregression_ensemble_ClassifierChain_tfidf[0])):\n",
    "        temp.append(int(predict_logisticregression_ensemble_ClassifierChain_tfidf[i][j]+0.8))\n",
    "    org.append(temp)\n",
    "    temp = []\n",
    "    \n",
    "predict_logisticregression_ensemble_ClassifierChain_tfidf = np.asarray(org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = CC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "cc.fit(x_train,y_train)\n",
    "save_model(cc,'LogisticRegression_tfidf_CC.sav','tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_CC_ClassifierChain_tfidf=cc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br = BR(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "br.fit(x_train,y_train)\n",
    "save_model(br,'LogisticRegression_tfidf_BR.sav','tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_BR_ClassifierChain_tfidf=br.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcc = MCC(h=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=False,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', solver='sag', tol=0.0001,\n",
    "          verbose=0, warm_start=False))\n",
    "mcc.fit(x_train,y_train)\n",
    "save_model(mcc,'LogisticRegression_tfidf_MCC.sav','tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_MCC_ClassifierChain_tfidf=mcc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.3 visualization and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_logisticregression_ensemble_ClassifierChain_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score_prediction_logisticregression_OneVsRestClassifier_tfidf = f1_score(y_test,prediction_logisticregression_OneVsRestClassifier_tfidf,average='weighted')\n",
    "f1_score_prediction_logisticregression_pure_ClassifierChain_tfidf = f1_score(y_test,predict_logisticregression_ensemble_ClassifierChain_tfidf,average='weighted')\n",
    "f1_score_logisticregression_CC_ClassifierChain_tfidf = f1_score(y_test,predict_logisticregression_CC_ClassifierChain_tfidf,average='weighted')\n",
    "f1_score_logisticregression_BR_ClassifierChain_tfidf = f1_score(y_test,predict_logisticregression_BR_ClassifierChain_tfidf,average='weighted')\n",
    "f1_score_logisticregression_MCC_ClassifierChain_tfidf = f1_score(y_test,predict_logisticregression_MCC_ClassifierChain_tfidf,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_logisticregression_OneVsRestClassifier_tfidf: ',f1_score_prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "print('f1_score_prediction_logisticregression_pure_chain_tfidf: ',f1_score_prediction_logisticregression_pure_ClassifierChain_tfidf)\n",
    "print('f1_score_logisticregression_CC_ClassifierChain_tfidf: ',f1_score_logisticregression_CC_ClassifierChain_tfidf)\n",
    "print('f1_score_logisticregression_BR_ClassifierChain_tfidf: ',f1_score_logisticregression_BR_ClassifierChain_tfidf)\n",
    "print('f1_score_logisticregression_MCC_ClassifierChain_tfidf: ',f1_score_logisticregression_MCC_ClassifierChain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hamming_loss_prediction_logisticregression_OneVsRestClassifier_tfidf = Hamming_loss(y_test,prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "Hamming_loss_prediction_logisticregression_pure_ClassifierChain_tfidf = Hamming_loss(y_test,predict_logisticregression_ensemble_ClassifierChain_tfidf)\n",
    "Hamming_loss_logisticregression_CC_ClassifierChain_tfidf = Hamming_loss(y_test,predict_logisticregression_CC_ClassifierChain_tfidf)\n",
    "Hamming_loss_logisticregression_BR_ClassifierChain_tfidf = Hamming_loss(y_test,predict_logisticregression_BR_ClassifierChain_tfidf)\n",
    "Hamming_loss_logisticregression_MCC_ClassifierChain_tfidf = Hamming_loss(y_test,predict_logisticregression_MCC_ClassifierChain_tfidf)\n",
    "\n",
    "print('Hamming_loss_prediction_logisticregression_OneVsRestClassifier_tfidf: ',Hamming_loss_prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "print('Hamming_loss_prediction_logisticregression_pure_chain_tfidf: ',Hamming_loss_prediction_logisticregression_pure_ClassifierChain_tfidf)\n",
    "print('Hamming_loss_logisticregression_CC_ClassifierChain_tfidf: ',Hamming_loss_logisticregression_CC_ClassifierChain_tfidf)\n",
    "print('Hamming_loss_logisticregression_BR_ClassifierChain_tfidf: ',Hamming_loss_logisticregression_BR_ClassifierChain_tfidf)\n",
    "print('Hamming_loss_logisticregression_MCC_ClassifierChain_tfidf: ',Hamming_loss_logisticregression_MCC_ClassifierChain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hamming_score_prediction_logisticregression_OneVsRestClassifier_tfidf = Hamming_score(y_test,prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "Hamming_score_prediction_logisticregression_pure_ClassifierChain_tfidf = Hamming_score(y_test,predict_logisticregression_ensemble_ClassifierChain_tfidf)\n",
    "Hamming_score_logisticregression_CC_ClassifierChain_tfidf = Hamming_score(y_test,predict_logisticregression_CC_ClassifierChain_tfidf)\n",
    "Hamming_score_logisticregression_BR_ClassifierChain_tfidf = Hamming_score(y_test,predict_logisticregression_BR_ClassifierChain_tfidf)\n",
    "Hamming_score_logisticregression_MCC_ClassifierChain_tfidf = Hamming_score(y_test,predict_logisticregression_MCC_ClassifierChain_tfidf)\n",
    "\n",
    "print('Hamming_score_prediction_logisticregression_OneVsRestClassifier_tfidf: ',Hamming_score_prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "print('Hamming_score_prediction_logisticregression_pure_chain_tfidf: ',Hamming_score_prediction_logisticregression_pure_ClassifierChain_tfidf)\n",
    "print('Hamming_score_logisticregression_CC_ClassifierChain_tfidf: ',Hamming_score_logisticregression_CC_ClassifierChain_tfidf)\n",
    "print('Hamming_score_logisticregression_BR_ClassifierChain_tfidf: ',Hamming_score_logisticregression_BR_ClassifierChain_tfidf)\n",
    "print('Hamming_score_logisticregression_MCC_ClassifierChain_tfidf: ',Hamming_score_logisticregression_MCC_ClassifierChain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Exact_match_prediction_logisticregression_OneVsRestClassifier_tfidf = Exact_match(y_test,prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "Exact_match_prediction_logisticregression_pure_ClassifierChain_tfidf = Exact_match(y_test,predict_logisticregression_ensemble_ClassifierChain_tfidf)\n",
    "Exact_match_logisticregression_CC_ClassifierChain_tfidf = Exact_match(y_test,predict_logisticregression_CC_ClassifierChain_tfidf)\n",
    "Exact_match_logisticregression_BR_ClassifierChain_tfidf = Exact_match(y_test,predict_logisticregression_BR_ClassifierChain_tfidf)\n",
    "Exact_match_logisticregression_MCC_ClassifierChain_tfidf = Exact_match(y_test,predict_logisticregression_MCC_ClassifierChain_tfidf)\n",
    "\n",
    "print('Exact_match_prediction_logisticregression_OneVsRestClassifier_tfidf: ',Exact_match_prediction_logisticregression_OneVsRestClassifier_tfidf)\n",
    "print('Exact_match_prediction_logisticregression_pure_chain_tfidf: ',Exact_match_prediction_logisticregression_pure_ClassifierChain_tfidf)\n",
    "print('Exact_match_logisticregression_CC_ClassifierChain_tfidf: ',Exact_match_logisticregression_CC_ClassifierChain_tfidf)\n",
    "print('Exact_match_logisticregression_BR_ClassifierChain_tfidf: ',Exact_match_logisticregression_BR_ClassifierChain_tfidf)\n",
    "print('Exact_match_logisticregression_MCC_ClassifierChain_tfidf: ',Exact_match_logisticregression_MCC_ClassifierChain_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier_tfidf = DecisionTreeClassifier(min_samples_split=2, random_state=1)\n",
    "DecisionTreeClassifier_tfidf.fit(x_train,y_train)\n",
    "save_model(DecisionTreeClassifier_tfidf,'DecisionTreeClassifier_tfidf.sav','tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_DecisionTreeClassifier_tfidf = DecisionTreeClassifier_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_prediction_DecisionTreeClassifier_tfidf:  0.262341236935\n"
     ]
    }
   ],
   "source": [
    "f1_score_DecisionTreeClassifier_tfidf = f1_score(y_test,predict_DecisionTreeClassifier_tfidf,average='weighted')\n",
    "\n",
    "print('f1_score_prediction_DecisionTreeClassifier_tfidf: ',f1_score_DecisionTreeClassifier_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss_DecisionTreeClassifier_tfidf:  0.111428571429\n"
     ]
    }
   ],
   "source": [
    "Hamming_loss_DecisionTreeClassifier_tfidf = Hamming_loss(y_test,predict_DecisionTreeClassifier_tfidf)\n",
    "\n",
    "print('Hamming_loss_DecisionTreeClassifier_tfidf: ',Hamming_loss_DecisionTreeClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_score_DecisionTreeClassifier_tfidf:  0.888571428571\n"
     ]
    }
   ],
   "source": [
    "Hamming_score_DecisionTreeClassifier_tfidf = Hamming_score(y_test,predict_DecisionTreeClassifier_tfidf)\n",
    "\n",
    "print('Hamming_score_DecisionTreeClassifier_tfidf: ',Hamming_score_DecisionTreeClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact_match_DecisionTreeClassifier_tfidf:  0.03\n"
     ]
    }
   ],
   "source": [
    "Exact_match_DecisionTreeClassifier_tfidf = Exact_match(y_test,predict_DecisionTreeClassifier_tfidf)\n",
    "\n",
    "print('Exact_match_DecisionTreeClassifier_tfidf: ',Exact_match_DecisionTreeClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# bp mll loss function\n",
    "# y_true, y_pred must be 2D tensors of shape (batch dimension, number of labels)\n",
    "# y_true must satisfy y_true[i][j] == 1 iff sample i has label j\n",
    "def bp_mll_loss(y_true, y_pred):\n",
    " \n",
    "    # get true and false labels\n",
    "    y_i = K.equal(y_true, K.ones_like(y_true))\n",
    "    y_i_bar = K.not_equal(y_true, K.ones_like(y_true))\n",
    "    \n",
    "    # cast to float as keras backend has no logical and\n",
    "    y_i = K.cast(y_i, dtype='float32')\n",
    "    y_i_bar = K.cast(y_i_bar, dtype='float32')\n",
    "\n",
    "    # get indices to check\n",
    "    truth_matrix = pairwise_and(y_i, y_i_bar)\n",
    "\n",
    "    # calculate all exp'd differences\n",
    "    sub_matrix = pairwise_sub(y_pred, y_pred)\n",
    "    exp_matrix = K.exp(-sub_matrix)\n",
    "\n",
    "    # check which differences to consider and sum them\n",
    "    sparse_matrix = exp_matrix * truth_matrix\n",
    "    sums = K.sum(sparse_matrix, axis=[1,2])\n",
    "\n",
    "    # get normalizing terms and apply them\n",
    "    y_i_sizes = K.sum(y_i, axis=1)\n",
    "    y_i_bar_sizes = K.sum(y_i_bar, axis=1)\n",
    "    normalizers = y_i_sizes * y_i_bar_sizes\n",
    "    results = sums / normalizers\n",
    "\n",
    "    # sum over samples\n",
    "    return K.sum(results)\n",
    "\n",
    "\n",
    "# compute pairwise differences between elements of the tensors a and b\n",
    "def pairwise_sub(a, b):\n",
    "    column = K.expand_dims(a, 2)\n",
    "    row = K.expand_dims(b, 1)\n",
    "    return column - row\n",
    "\n",
    "# compute pairwise logical and between elements of the tensors a and b\n",
    "def pairwise_and(a, b):\n",
    "    column = K.expand_dims(a, 2)\n",
    "    row = K.expand_dims(b, 1)\n",
    "    return K.minimum(column, row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = x_train.shape[0]\n",
    "dim_no = x_train.shape[1]\n",
    "class_no = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 24.9179\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 22.4449\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 22.0011\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 21.7054\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 21.4001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123968f60>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "\n",
    "# create simple mlp\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=dim_no, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(class_no, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "model.compile(loss=bp_mll_loss, optimizer='adagrad', metrics=[])\n",
    "\n",
    "# train a few epochs\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(100, 28)\n",
      "[  1.07279792e-02   5.53013012e-03   1.21583402e-01   9.89946544e-01\n",
      "   1.79836573e-03   3.03064415e-04   6.69351313e-03   2.30080143e-01\n",
      "   3.92278701e-01   9.97813106e-01   1.79367676e-01   7.82854203e-03\n",
      "   1.58002064e-01   3.92395863e-03   1.11133792e-02   9.61005449e-01\n",
      "   2.86067128e-01   6.74827471e-02   1.28031686e-01   1.25051722e-01\n",
      "   4.78469402e-01   1.26170516e-01   2.34149001e-03   9.96589899e-01\n",
      "   4.57244478e-02   3.09328362e-03   9.35036018e-02   4.74386178e-02]\n",
      "[[ 0.01380529  0.00642244  0.12232939 ...,  0.00409534  0.11350527\n",
      "   0.06305631]\n",
      " [ 0.00726808  0.00329856  0.10542663 ...,  0.00181003  0.07346009\n",
      "   0.03900498]\n",
      " [ 0.01072798  0.00553013  0.1215834  ...,  0.00309328  0.0935036\n",
      "   0.04743862]\n",
      " ..., \n",
      " [ 0.00600706  0.00262066  0.10390926 ...,  0.00140605  0.06460322\n",
      "   0.03301838]\n",
      " [ 0.01786968  0.01000424  0.15377772 ...,  0.00623577  0.11988172\n",
      "   0.0688329 ]\n",
      " [ 0.00463269  0.00193006  0.08776482 ...,  0.00101964  0.06270926\n",
      "   0.03015795]]\n",
      "[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] res\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.38      0.53      0.44        32\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         1\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.00      0.00      0.00         6\n",
      "          9       0.34      0.84      0.48        37\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00         7\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       1.00      0.08      0.14        26\n",
      "         16       0.00      0.00      0.00        10\n",
      "         17       0.00      0.00      0.00         8\n",
      "         18       0.00      0.00      0.00         3\n",
      "         19       0.00      0.00      0.00         4\n",
      "         20       0.00      0.00      0.00         7\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.42      0.89      0.57        38\n",
      "         24       0.00      0.00      0.00         2\n",
      "         25       0.00      0.00      0.00         0\n",
      "         26       0.00      0.00      0.00         2\n",
      "         27       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.31      0.39      0.26       218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bpmll_Word2Vec = model.predict(x_test)\n",
    "\n",
    "\n",
    "#report =classification_report(Y_test, bpmll_Word2Vec)\n",
    "print (len(bpmll_Word2Vec))\n",
    "\n",
    "print (bpmll_Word2Vec.shape)\n",
    "\n",
    "b = bpmll_Word2Vec[2][0]\n",
    "\n",
    "a = bpmll_Word2Vec\n",
    "\n",
    "res = []\n",
    "tmp = []\n",
    "for j in range(bpmll_Word2Vec.shape[0]):\n",
    "\tfor i in range(bpmll_Word2Vec.shape[1]):\n",
    "\t\ttmp.append(int(bpmll_Word2Vec[j][i]+0.01))\n",
    "\tres.append(tmp)\n",
    "\ttmp = []\t\n",
    "\n",
    "print(bpmll_Word2Vec[2])\n",
    "\n",
    "print(a)\n",
    "print(y_test[2])\n",
    "res = pd.DataFrame(res)\n",
    "res = res.as_matrix()\n",
    "print(res,'res')\n",
    "report =classification_report(y_test, res)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0960714285714\n",
      "0.903928571429\n",
      "0.04\n"
     ]
    }
   ],
   "source": [
    "print(Hamming_loss(y_test, res))\n",
    "print(Hamming_score(y_test, res))\n",
    "print(Exact_match(y_test, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
